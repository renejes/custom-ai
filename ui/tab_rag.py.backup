"""
RAG Data Preparation Tab UI
Handles document upload, processing, and database export.
"""

import gradio as gr
import os
import subprocess
import platform
from pathlib import Path
from typing import List, Optional
from core.rag_processor import RAGProcessor
from core.project_manager import ProjectManager


def create_rag_tab(project_manager: ProjectManager):
    """
    Create RAG data preparation tab.

    Args:
        project_manager: ProjectManager instance

    Returns:
        Gradio components for the tab
    """

    # State variables
    uploaded_files_state = gr.State([])

    def upload_files(files) -> tuple:
        """Handle file uploads."""
        if not files:
            return [], "No files uploaded", gr.update()

        # Store uploaded files
        file_data = []
        for file in files:
            file_data.append({
                "name": os.path.basename(file.name),
                "path": file.name,
                "status": "Uploaded",
                "chunks": 0
            })

        # Create table data
        table_data = [[f["name"], f["status"]] for f in file_data]

        message = f" Uploaded {len(files)} file(s)"

        return file_data, message, gr.update(value=table_data)

    def process_documents(uploaded_files, chunk_size, chunk_overlap, overwrite) -> tuple:
        """Process uploaded documents."""
        project = project_manager.get_current_project()

        if not project:
            return uploaded_files, "L Error: No project selected. Please create or select a project first.", gr.update(), gr.update()

        if not uploaded_files:
            return uploaded_files, "L Error: No files uploaded. Please upload documents first.", gr.update(), gr.update()

        # Initialize RAG processor
        db_path = str(project.get_rag_db_path())
        processor = RAGProcessor(
            db_path=db_path,
            chunk_size=int(chunk_size),
            chunk_overlap=int(chunk_overlap)
        )

        # Process files
        file_paths = [f["path"] for f in uploaded_files]
        results = processor.process_files(file_paths, overwrite=overwrite)

        # Update file data with results
        updated_files = []
        for file_info in uploaded_files:
            # Find result for this file
            detail = next((d for d in results["details"] if d["filename"] == file_info["name"]), None)

            if detail:
                file_info["status"] = " Processed" if detail["success"] else "L Failed"
                file_info["chunks"] = detail["chunks"]
            updated_files.append(file_info)

        # Create table data
        table_data = [[f["name"], f["status"]] for f in updated_files]

        # Create log message
        log_lines = [
            f"=ï¿½ Processing Results:",
            f"   Total files: {results['total_files']}",
            f"   Successful: {results['successful']}",
            f"   Failed: {results['failed']}",
            f"   Total chunks: {results['total_chunks']}",
            "",
            "=ï¿½ Details:"
        ]

        for detail in results["details"]:
            status_icon = "" if detail["success"] else "L"
            log_lines.append(f"   {status_icon} {detail['filename']}: {detail['message']}")

        # Get updated stats
        stats = processor.get_stats()
        log_lines.extend([
            "",
            "=ï¿½ Database Stats:",
            f"   Total documents: {stats['total_documents']}",
            f"   Total chunks: {stats['total_chunks']}",
            f"   Database size: {stats['database_size_mb']} MB"
        ])

        # Update project config
        project.update_config({
            "rag": {
                "chunk_size": chunk_size,
                "chunk_overlap": chunk_overlap,
                "documents_processed": stats['total_documents'],
                "total_chunks": stats['total_chunks']
            }
        })

        log_message = "\n".join(log_lines)

        return updated_files, log_message, gr.update(value=table_data), gr.update(value=get_stats_summary(project))

    def get_stats_summary(project) -> str:
        """Get current database statistics."""
        if not project:
            return "No project selected"

        db_path = str(project.get_rag_db_path())

        if not os.path.exists(db_path):
            return "No database created yet. Upload and process documents to get started."

        processor = RAGProcessor(db_path)
        stats = processor.get_stats()

        summary = f"""
**Database Statistics:**
- Documents: {stats['total_documents']}
- Chunks: {stats['total_chunks']}
- Size: {stats['database_size_mb']} MB
- Path: `{stats['database_path']}`
"""
        return summary

    def export_database() -> str:
        """Export database and open file location."""
        project = project_manager.get_current_project()

        if not project:
            return "L Error: No project selected"

        db_path = project.get_rag_db_path()

        if not os.path.exists(db_path):
            return "L Error: No database found. Process documents first."

        # Open file manager at database location
        try:
            db_dir = os.path.dirname(db_path)

            if platform.system() == "Darwin":  # macOS
                subprocess.run(["open", db_dir])
            elif platform.system() == "Windows":
                subprocess.run(["explorer", db_dir])
            else:  # Linux
                subprocess.run(["xdg-open", db_dir])

            return f" Database exported!\n\nLocation: {db_path}\n\nFile manager opened at project data folder."
        except Exception as e:
            return f" Database ready for export!\n\nLocation: {db_path}\n\n(Could not open file manager: {e})"

    def clear_uploads(uploaded_files) -> tuple:
        """Clear uploaded files."""
        return [], "Uploads cleared", gr.update(value=[])

    # Build UI
    with gr.Column():
        gr.Markdown("""
        ## =ï¿½ RAG Data Preparation

        Upload documents (PDF, TXT, MD, DOCX) to create a knowledge base for your model.
        Documents will be chunked and stored in a SQLite database.
        """)

        # Upload section
        with gr.Row():
            file_upload = gr.File(
                label="Upload Documents",
                file_count="multiple",
                file_types=[".pdf", ".txt", ".md", ".docx", ".html", ".htm", ".ipynb", ".csv", ".xlsx", ".json"],
                interactive=True
            )

        upload_status = gr.Textbox(
            label="Upload Status",
            interactive=False,
            lines=1
        )

        # Document table
        document_table = gr.Dataframe(
            headers=["Filename", "Status"],
            label="Uploaded Documents",
            interactive=False,
            wrap=True
        )

        # Processing settings
        with gr.Accordion("ï¿½ Processing Settings", open=False):
            with gr.Row():
                chunk_size = gr.Number(
                    label="Chunk Size (characters)",
                    value=512,
                    minimum=100,
                    maximum=2000,
                    step=50,
                    info="Number of characters per chunk"
                )
                chunk_overlap = gr.Number(
                    label="Chunk Overlap (characters)",
                    value=50,
                    minimum=0,
                    maximum=500,
                    step=10,
                    info="Overlap between consecutive chunks"
                )

            overwrite = gr.Checkbox(
                label="Overwrite existing documents",
                value=False,
                info="If checked, reprocess documents that are already in the database"
            )

        # Action buttons
        with gr.Row():
            process_btn = gr.Button("= Process Documents", variant="primary", scale=2)
            clear_btn = gr.Button("=ï¿½ Clear Uploads", scale=1)
            export_btn = gr.Button("=ï¿½ Export Database", scale=1)

        # Processing log
        processing_log = gr.Textbox(
            label="Processing Log",
            lines=12,
            interactive=False,
            placeholder="Upload and process documents to see logs here..."
        )

        # Database stats
        with gr.Accordion("=ï¿½ Database Statistics", open=False):
            stats_display = gr.Markdown(get_stats_summary(project_manager.get_current_project()))

        # Wire up events
        file_upload.change(
            fn=upload_files,
            inputs=[file_upload],
            outputs=[uploaded_files_state, upload_status, document_table]
        )

        process_btn.click(
            fn=process_documents,
            inputs=[uploaded_files_state, chunk_size, chunk_overlap, overwrite],
            outputs=[uploaded_files_state, processing_log, document_table, stats_display]
        )

        clear_btn.click(
            fn=clear_uploads,
            inputs=[uploaded_files_state],
            outputs=[uploaded_files_state, upload_status, document_table]
        )

        export_btn.click(
            fn=export_database,
            outputs=[processing_log]
        )

    return {
        "uploaded_files_state": uploaded_files_state,
        "stats_display": stats_display
    }
